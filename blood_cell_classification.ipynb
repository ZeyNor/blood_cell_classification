{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ace4c691247b8b1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Blood Cell Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff09bf4b51e5f94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T19:14:45.616143653Z",
     "start_time": "2023-08-18T19:14:45.606933028Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3dff1e91f34382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T19:14:49.667547853Z",
     "start_time": "2023-08-18T19:14:49.623141251Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6660f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 22:51:09.728618: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-18 22:51:09.754080: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-18 22:51:10.162521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, MaxPool2D, Flatten\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4bff1e",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a952ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = image.ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9b9a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9957 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = generator.flow_from_directory(\n",
    "    shuffle = True,\n",
    "    batch_size = 32,\n",
    "    target_size = (80, 80),\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training',\n",
    "    directory = 'datasets/dataset2-master/dataset2-master/images/TRAIN'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6c3b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2eb9d7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c194676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides = (1, 1), activation = 'relu', input_shape = (80, 80, 3)))\n",
    "    model.add(Conv2D(80, (3,3), strides = (1, 1), activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2,2)))\n",
    "    model.add(Conv2D(64, (3,3), strides = (1,1), activation = 'relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])\n",
    "    model.build(dataset.image_shape)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db9d2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 78, 78, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 76, 76, 80)        46160     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 38, 38, 80)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 36, 36, 64)        46144     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 36, 36, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 82944)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               10616960  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10711572 (40.86 MB)\n",
      "Trainable params: 10711572 (40.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = model_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea8da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 22:51:40.175345: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nn.fit(dataset, steps_per_epoch = None, epochs = 30, verbose = 1)\n",
    "nn.save('Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
